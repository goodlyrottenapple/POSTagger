module Main where
import Parser
import Core
import Alg

import Data.List.Split (splitOn)
import Data.List (tails, intercalate)
import qualified Data.Map as M
import System.Environment
import System.IO
import System.Directory    
import Text.Regex.Posix
import Control.Monad


-- given a directory path, returns all the paths for files with the extension .POS in the same directory
getAllDataFilePaths :: FilePath -> IO [FilePath]
getAllDataFilePaths f = do
    allFiles <- getDirectoryContents f
    -- add the ".POS" files to the one returned by ret
    return $ map ((f ++ "/") ++ ) $ filter (\path -> path =~ ".+\\.POS" :: Bool) allFiles

-- given a directory path, returns all the paths of the folders inside the given directory
getFolders :: FilePath -> IO [FilePath]
getFolders f = do
    allFiles <- getDirectoryContents f
    -- compute all the files in the current directory
    filterM doesDirectoryExist $ map (f ++) $ filter (\path -> not (path =~ "\\.+" :: Bool)) allFiles

-- given a directory path, returns all the paths for files with the extension .POS (recurses into folders within the directory)
getAllDataFilePathsRec :: FilePath -> IO [FilePath]
getAllDataFilePathsRec f = do
    allFiles <- getDirectoryContents f
    -- compute all the files in the current directory
    dirs <- filterM doesDirectoryExist $ map (f ++) $ filter (\path -> not (path =~ "\\.+" :: Bool)) allFiles
    -- recursively find all the files ending in ".POS"
    ret <- foldM (\acc f -> getAllDataFilePathsRec f >>= \res -> return $ acc ++ res) [] dirs 
    -- add the ".POS" files to the one returned by ret
    return $ (map ((f ++ "/") ++ ) $ filter (\path -> path =~ ".+\\.POS" :: Bool) allFiles) ++ ret

-- given a list of files of the corpus (text files with .POS extension)
-- generates three files:
--     tCount.txt <- contains all the found tags along with the number of times they appear in the corpus
--     ttCount.txt <- contains the number of apeearances of all the bigrams in the corpus
--     wtCount.txt <- contains word + tag + the number of times that word + tag appear in the corpus
genAndSaveCounts :: [FilePath] -> FilePath -> IO ()
genAndSaveCounts files fileName = do
    Just parsed <- parseFiles files
    let x = map startEndTags parsed
        wtMap = genWordTagOccsMap x
        ttMap = genTagTagOccsMap x
        tMap = genTagOccsMap x in do
            writeFile (fileName ++ "tCount.txt") (tagCountMapToStr tMap)
            writeFile (fileName ++ "ttCount.txt") (strStrCountMapToStr ttMap)
            writeFile (fileName ++ "wtCount.txt") (strStrCountMapToStr wtMap)
    
-- given the corpus (as a list of processed sentences (list of word pair tags)),
-- generates the two probability functions and returns the list of all the tags found in the corpus.
genProbsFromSentences :: [Sentence] -> IO (WordTagProb, TagTagProb, [Tag])
genProbsFromSentences parsed = let
    x = map startEndTags parsed
    wtMap = genWordTagOccsMap x
    ttMap = genTagTagOccsMap x
    tMap = genTagOccsMap x
    pTT = genTagTagProbFun tMap ttMap
    pWT = genWordTagProbFun tMap wtMap
    tags = M.keys $ tMap in return (pWT, pTT, tags)


-- given the corpus (as a list of processed sentences (list of word pair tags)),
-- and wtCount.txt, which is the text file containing the words with associated tagsa and the number of thier occurence
-- generates the two probability functions and returns the list of all the tags found in the corpus.
genProbsFromSentencesNoUnknown :: [Sentence] -> IO (WordTagProb, TagTagProb, [Tag])
genProbsFromSentencesNoUnknown parsed = do
    wtMapStr <- readFile ("./wtCount.txt")
    let
        x = map startEndTags parsed
        wtMap = (genWordTagOccsMap x) `M.union` wtMapAllWords
        wtMapAllWords = strToStrStrCountMap wtMapStr
        ttMap = genTagTagOccsMap x
        tMap = genTagOccsMap x
        pTT = genTagTagProbFun tMap ttMap
        pWT = genWordTagProbFun tMap wtMap
        tags = M.keys $ tMap in return (pWT, pTT, tags)


-- given a path which concains tCount.txt, ttCount.txt and wtCount.txt (generated by genAndSaveCounts)
-- reads the contents of each file and generates the two probability functions and returns the list of all the tags found in this portion of the corpus.
genProbsFromProcessedFile :: FilePath -> IO (WordTagProb, TagTagProb, [Tag])
genProbsFromProcessedFile fp = do
    tMapStr <- readFile (fp ++ "tCount.txt")
    ttMapStr <- readFile (fp ++ "ttCount.txt")
    wtMapStr <- readFile (fp ++ "wtCount.txt")
    let wtMap = strToStrStrCountMap wtMapStr
        ttMap = strToStrStrCountMap ttMapStr
        tMap = strToTagCountMap tMapStr
        pTT = genTagTagProbFun tMap ttMap
        pWT = genWordTagProbFun tMap wtMap
        tags = M.keys $ tMap in return (pWT, pTT, tags)



-- a helper function that filters out all the elements that occur in y from x
(\\) :: Eq a => [a] -> [a] -> [a]
x \\ y = filter (\z -> not $ z `elem` y) x


-- rather inefficient, but who cares, the card of these is usually no more than 1.
subset :: Eq a => [a] -> [a] -> Bool
subset [] _ = True
subset (x:xs) y = if x `elem` y then subset xs y else False

-- adapted from https://wiki.haskell.org/99_questions/Solutions/26
partition :: Eq a => Int -> [a] -> [([a], [a])]
partition 0 _  = [([],[])]
partition n xs = [ (y:ys, xs \\ (y:ys)) | y:xs' <- tails xs, (ys, _) <- partition (n-1) xs']

-- strips the given sentence of its tags (producing [Word]) and turns all words into lower case,
-- since the corpus has also been normalized this way, then runs the viterbi algorithm (passed in as v)
runViterbi :: ([Core.Word] -> [Tag]) -> Sentence -> [Tag]
runViterbi v = v . map lowerCase . map word

-- given a sentence and a list of tags (produced by running the viterbi algorithm on the sentence using runViterbi),
-- produces a list of triples of incorrectly matched words, along with the correct tag/s and the tag produced by the viterbi alg.
incorrectTags :: Sentence -> [Tag] -> [(Core.Word, [Tag], Tag)]
incorrectTags [] _ = []
incorrectTags ((w,tl):xs) (t:ts) = if t `elem` tl then incorrectTags xs ts else (w, tl, t):(incorrectTags xs ts)


generateStats :: ([Sentence] -> IO (WordTagProb, TagTagProb, [Tag])) -> ([FilePath], [FilePath]) -> IO (Int, Int)
generateStats genFunction (testing_f, corpus_f) = do
    testing <- foldM (\acc f -> getAllDataFilePathsRec f >>= \res -> return $ acc ++ res) [] testing_f
    corpus <- foldM (\acc f -> getAllDataFilePathsRec f >>= \res -> return $ acc ++ res) [] corpus_f
    -- putStrLn $ show corpus_f
    Just parsed_c <- parseFiles corpus
    Just parsed_t <- parseFiles testing
    (wtProb, ttProb, tags) <- genFunction parsed_c -- genProbsFromProcessedFile "./"

    -- putStrLn $ show tags

    let total = sum $ map length parsed_t
        v = viterbi tags wtProb ttProb
        incorrect = sum $ map (\s -> length $ incorrectTags s (runViterbi v s) {-`debug` (show s ++ "\n\n" ++ show (incorrectTags s (runViterbi v s)) ++ "\n\n\n")-} ) parsed_t in do
            putStrLn $ show testing_f
            putStrLn $ "INCORRECT: " ++ show incorrect
            putStrLn $ "TOTAL: " ++ show total
            return (incorrect, total)




{-findArgWOpts :: String -> Int -> [String] -> Maybe [String]
findArgWOpts arg 0 [] = Nothing
findArgWOpts arg 0 (a:as) = if a == arg then Just [] else findArgWOpts arg 0 as
findArgWOpts arg n [] = Nothing
findArgWOpts arg n [a] = Nothing
findArgWOpts arg n (x:xs) = 
    if x == arg then 
        if length args == n then Just args else Nothing
    else findArgWOpts arg n xs
    where args = take n xs-}

-- usage = putStrLn "These are valid args: \ngenerate probabilities: -gp <file>"

main = do
    -- args <- getArgs
    -- case findArgWOpts "-gp" 1 args of
    --     Just [fp] -> do
    --         files <- getAllDataFilePathsRec "fp"
    --         case files of 
    --             [] -> putStrLn "No files found"
    --             x -> genAndSaveCounts x ""
    --     Nothing -> usage

{-    files <- getAllDataFilePathsRec "./data/"
    -- files <- getAllDataFilePaths "."
-}

    -- files <- getAllDataFilePaths "."




    folders <- getFolders "./data/"

    let p = partition 1 folders in do
        -- putStrLn $ show p
        l <- mapM (generateStats genProbsFromSentencesNoUnknown) p
        let 
            i = sum (map fst l)
            t = sum (map snd l) in 
            putStrLn $ "incorrect: " ++ show i ++ 
            "\ntotal: " ++ show t ++ "\n" ++
            show ((fromIntegral i) / (fromIntegral t) * 100)






    -- parsed <- parseFiles files
    -- case parsed of
    --     Just r -> do
    --         tMapStr <- readFile "tCount.txt"
    --         ttMapStr <- readFile "ttCount.txt"
    --         wtMapStr <- readFile "wtCount.txt"

    --         let
    --             wtMap = strToStrStrCountMap wtMapStr
    --             ttMap = strToStrStrCountMap ttMapStr
    --             tMap = strToTagCountMap tMapStr
    --             pTT = genTagTagProbFun tMap ttMap
    --             pWT = genWordTagProbFun tMap wtMap
    --             tags = M.keys $ tMap 
    --             v = viterbi tags pWT pTT in 
    --                 putStr $ intercalate "\n\n" $ map (\s -> show (intercalate " " $ map word s) ++ "\n" ++ show (incorrectTags s (runViterbi v s))) r



 {-   tMapStr <- readFile "tCount.txt"
    ttMapStr <- readFile "ttCount.txt"
    wtMapStr <- readFile "wtCount.txt"

    let
        wtMap = strToStrStrCountMap wtMapStr
        ttMap = strToStrStrCountMap ttMapStr
        tMap = strToTagCountMap tMapStr
        pTT = genTagTagProbFun tMap ttMap
        pWT = genWordTagProbFun tMap wtMap
        tags = M.keys $ tMap 
        i = initScore pWT pTT "he" tags in
        
        -- putStr $ (show $ initScore pWT pTT "he" tags) ++ "\n\n" ++ (show $ last $ sortBy (comparing snd) $ M.toList $ initScore pWT pTT "he" tags)

        -- putStr $ (show $ last $ sortBy (comparing snd) $ [(t, pWT ("he",t)) | t <- tags]) ++ "\n\n\n" ++ (show $ last $ sortBy (comparing snd) $ [(t, pWT ("was",t)) | t <- tags])  ++ "\n\n\n" ++ (show [(t, pTT ("VBD",t)) | t <- tags])
        -- putStr $ show $ pWT ("he", "NN")

        putStr $ show $ viterbi tags pWT pTT (splitOn " " "he was a sandwich .")-}

