module Main where
import Core
import Parser
import Alg

import qualified Data.Map as M
import System.Directory (doesDirectoryExist, getDirectoryContents)
import Text.Regex.Posix
import Control.Monad (foldM, filterM)

-- given a directory path, returns all the paths for files with the extension .POS (recurses into folders within the directory)
getAllDataFilePathsRec :: FilePath -> IO [FilePath]
getAllDataFilePathsRec f = do
    allFiles <- getDirectoryContents f
    -- compute all the files in the current directory
    dirs <- filterM doesDirectoryExist $ map (f ++) $ filter (\path -> not (path =~ "\\.+" :: Bool)) allFiles
    -- recursively find all the files ending in ".POS"
    ret <- foldM (\acc f -> getAllDataFilePathsRec f >>= \res -> return $ acc ++ res) [] dirs 
    -- add the ".POS" files to the one returned by ret
    return $ (map ((f ++ "/") ++ ) $ filter (\path -> path =~ ".+\\.POS" :: Bool) allFiles) ++ ret

-- given a list of files of the corpus (text files with .POS extension)
-- generates three files:
--     tCount.txt <- contains all the found tags along with the number of times they appear in the corpus
--     ttCount.txt <- contains the number of apeearances of all the bigrams in the corpus
--     wtCount.txt <- contains word + tag + the number of times that word + tag appear in the corpus
genAndSaveCounts :: [FilePath] -> FilePath -> IO ()
genAndSaveCounts files fileName = do
    Just parsed <- parseFiles files
    let x = map startEndTags parsed
        wtMap = genWordTagOccsMap x
        ttMap = genTagTagOccsMap x
        tMap = genTagOccsMap x in do
            writeFile (fileName ++ "tCount.txt") (tagCountMapToStr tMap)
            writeFile (fileName ++ "ttCount.txt") (strStrCountMapToStr ttMap)
            writeFile (fileName ++ "wtCount.txt") (strStrCountMapToStr wtMap)
    
-- given the corpus (as a list of processed sentences (list of word pair tags)),
-- generates the two probability functions and returns the list of all the tags found in the corpus.
genProbsFromSentences :: [Sentence] -> IO (WordTagProb, TagTagProb, [Tag])
genProbsFromSentences parsed = let
    x = map startEndTags parsed
    wtMap = genWordTagOccsMap x
    ttMap = genTagTagOccsMap x
    tMap = genTagOccsMap x
    pTT = genTagTagProbFun tMap ttMap
    pWT = genWordTagProbFun tMap wtMap
    tags = M.keys $ tMap in return (pWT, pTT, tags)

-- given the corpus (as a list of processed sentences (list of word pair tags)),
-- and wtCount.txt, which is the text file containing the words with associated tagsa and the number of thier occurence
-- generates the two probability functions and returns the list of all the tags found in the corpus.
genProbsFromSentencesNoUnknown :: [Sentence] -> IO (WordTagProb, TagTagProb, [Tag])
genProbsFromSentencesNoUnknown parsed = do
    wtMapStr <- readFile ("./wtCount.txt")
    let
        x = map startEndTags parsed
        wtMapAllWords = strToStrStrCountMap wtMapStr
        wtMap = (genWordTagOccsMap x) `M.union` wtMapAllWords
        ttMap = genTagTagOccsMap x
        tMap = genTagOccsMap x
        pTT = genTagTagProbFun tMap ttMap
        pWT = genWordTagProbFun tMap wtMap
        tags = M.keys $ tMap in return (pWT, pTT, tags)

-- given a path which concains tCount.txt, ttCount.txt and wtCount.txt (generated by genAndSaveCounts)
-- reads the contents of each file and generates the two probability functions and returns the list of all the tags found in this portion of the corpus.
genProbsFromProcessedFile :: FilePath -> IO (WordTagProb, TagTagProb, [Tag])
genProbsFromProcessedFile fp = do
    tMapStr <- readFile (fp ++ "tCount.txt")
    ttMapStr <- readFile (fp ++ "ttCount.txt")
    wtMapStr <- readFile (fp ++ "wtCount.txt")
    let wtMap = strToStrStrCountMap wtMapStr
        ttMap = strToStrStrCountMap ttMapStr
        tMap = strToTagCountMap tMapStr
        pTT = genTagTagProbFun tMap ttMap
        pWT = genWordTagProbFun tMap wtMap
        tags = M.keys $ tMap in return (pWT, pTT, tags)


-- a helper function that filters out all the elements that occur in y from x
(\\) :: Eq a => [a] -> [a] -> [a]
x \\ y = filter (\z -> not $ z `elem` y) x


-- rather inefficient, but who cares, the card of these is usually no more than 1.
subset :: Eq a => [a] -> [a] -> Bool
subset [] _ = True
subset (x:xs) y = if x `elem` y then subset xs y else False


splitOnIth :: Int -> Int -> ([a], [a]) -> [a] -> ([a], [a])
splitOnIth _ _ r [] = r
splitOnIth i 0 (a,b) (x:xs) = splitOnIth i i (x:a, b) xs 
splitOnIth i j (a,b) (x:xs) = splitOnIth i (j-1) (a, x:b) xs

-- given a list, generates 10 different pairs of lists made up of the original list with a 10/90 split between the tuple of new lists
partition :: [a] -> [([a], [a])]
partition l = map (\i -> splitOnIth 9 i ([], []) l) [0..9]


-- strips the given sentence of its tags (producing [Word]) and turns all words into lower case,
-- since the corpus has also been normalized this way, then runs the viterbi algorithm (passed in as v)
runViterbi :: ([Core.Word] -> [Tag]) -> Sentence -> [Tag]
runViterbi v = v . map lowerCase . map word

-- given a sentence and a list of tags (produced by running the viterbi algorithm on the sentence using runViterbi),
-- produces a list of triples of incorrectly matched words, along with the correct tag/s and the tag produced by the viterbi alg.
incorrectTags :: Sentence -> [Tag] -> [(Core.Word, [Tag], Tag)]
incorrectTags [] _ = []
incorrectTags ((w,tl):xs) (t:ts) = if t `elem` tl then incorrectTags xs ts else (w, tl, t):(incorrectTags xs ts)


-- given a function that takes a corpus and generates the probability functions p(t1|t2) and p(w|t)
-- and a list of sentences for testing and the corpus, runs the viterbi algorithm on the testing set and
-- calculates the number of incorrect tags
generateStats :: ([Sentence] -> IO (WordTagProb, TagTagProb, [Tag])) -> ([Sentence], [Sentence]) -> IO (Int, Int)
generateStats genFunction (test, corpus) = do
    (wtProb, ttProb, tags) <- genFunction corpus
    putStrLn $ "--------------------------------\n\n--------------------------------"
    let total = sum $ map length test
        v = viterbi tags wtProb ttProb
        incorrect = sum $ map (\s -> length $ incorrectTags s (runViterbi v s) {-`debug` (show s ++ "\n\n" ++ show (incorrectTags s (runViterbi v s)) ++ "\n\n\n")-} ) test in do
            putStrLn $ "INCORRECT: " ++ show incorrect
            putStrLn $ "TOTAL: " ++ show total
            return (incorrect, total)


main = do
    files <- getAllDataFilePathsRec "./data/"
    Just parsed <- parseFiles files
    let p = partition parsed in do
        l <- mapM (generateStats genProbsFromSentencesNoUnknown) p
        putStrLn $ "average (no unknown words): " ++ show ( sum (map (\(w,t) -> fromIntegral (t-w) / fromIntegral t) l) * 10 )
        putStrLn ""
        l <- mapM (generateStats genProbsFromSentences) p
        putStrLn $ "average: " ++ show ( sum (map (\(w,t) -> fromIntegral (t-w) / fromIntegral t) l) * 10 )
